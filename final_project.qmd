---
title: "final_project"
format: pdf
---
```{r}
# Import all necessary libraries for the entire qmd file 
library(dplyr)
library(tidyr)
library(knitr)
library(kableExtra)
library(ggplot2)
library(janitor)
```

```{r}
# Goal: Tidy the world happiness data so each year is integrated into one
# data set. The resulting case is the happiness score for a country in a
# specific year. Then complete EDA analysis by creating summary tables of
# each feature and grouped by region. 

# Need: all of the separate world happiness data csv (2015, 2016, 2017, 2018, # and 2019)

# Plan
# 1a. Read in all of the individual data sets (2015, 2016, 2017, 2018, and 2019) from our github repository
# 2a. Tidy 2015 data
# 2b. Remove standard error column as only appear in 2015 data and no other
# analogs in the other data sets
# 2c. Add in year column so when merge all data sets together, know this data
# came from 2015
# 3a. Tidy 2016 data
# 3b. Remove confidence interval columns as only appear in 2016 data and no
# other analogs in the other data sets
# 3c. Add in year column so when merge all data sets together, know this data
# came from 2016
# 4a. Tidy 2017 data
# 4b. Remove whisker columns as only appear in 2017 data and no other analogs
# in the other data sets
# 4c. Add in year column so when merge all data sets together, know this data
# came from 2017
# 5a. Tidy 2018 data
# 5b. Rename columns in 2018 data so match with names of columns in 2015,
# 2016, and 2017 data
# 5c. Ensure government corruption treated as numeric, since numeric in all
# other data sets
# 5c. Add in year column so when merge all data sets together, know this data
# came from 2018
# 6a. Tidy 2019 data
# 6b. Rename columns in 2019 data so match with names of columns in 2015,
# 2016, 2017, and 2018 data
# 6c. Add in year column so when merge all data sets together, know this data
# came from 2019
# 7a. Merge all tidied year data by adding the rows of each data set into a
# total years data frame
# 8a. Scrap region information for 2017, 2018, and 2019 from the 2015 and
# 2016 data. (If the region is not listed in 2015/2016 or the country was not
# surveyed then, the information was left as null)
# 8b. Merge total years data with 2015 data by matching Country column
# 8c. Add Region column to total data merged with data from 2015. First, add
# regions already known for countries in 2015 and 2016. Then, add in regions
# for the countries  in other years that match the countries from the 2015
# data set.
# 8d. Merge total years data with 2016 data by matching Country column
# 8e. Add Region column to total data merged with data from 2016. First, add
# regions already known for countries in 2015 and 2016. Then, add in regions
# for the countries  in other years that match the countries from the 2016
# data set.
# 8f. Add new region data to final total data set
# 9a. Tidy final total data set
# 9b. Rename Family column to support system as this encompasses family and
# friends as social support
# 10a. Create a summary table based on each feature in the data set
# 10b. Summarize across the numeric columns in the total data set
# 10c. Get the measures of count, min, median, mean, max, and standard
# deviation for each column, allowing for NA values.
# 10d. Pivot longer so the case is a specific measure for each column
# 10e. Separate wider so the column name and measure each have their own
# column
# 10f. Pivot wider so each measure becomes a new column
# 11a. Create a summary table with a caption and kable styling.
# 12a. Create a summary table grouped by region for each feature in the data
# set
# 12b. Summarize across the numeric columns in the total data set
# 12c. Get the measures of count, min, median, mean, max, and standard
# deviation for each column, allowing for NA values.
# 12d. Pivot longer so the case is a specific measure for each column
# 12e. Separate wider so the column name and measure each have their own
# column
# 12f. Pivot wider so each measure becomes a new column
# 12g. Remove any NA's in the data set as those are countries whose region we
# don't know and therefore can remove in this region based table.
# 13a. Create a summary table with a caption and kable styling.
data_2015 <- read.csv("https://raw.githubusercontent.com/Stat184-Spring2025/Sec1_FP_Shania_Sree_Lauren/refs/heads/main/2015.csv")
#View(data_2015)

data_2016 <- read.csv("https://raw.githubusercontent.com/Stat184-Spring2025/Sec1_FP_Shania_Sree_Lauren/refs/heads/main/2016.csv")
#View(data_2016)

data_2017 <- read.csv("https://raw.githubusercontent.com/Stat184-Spring2025/Sec1_FP_Shania_Sree_Lauren/refs/heads/main/2017.csv")
#View(data_2017)

data_2018 <- read.csv("https://raw.githubusercontent.com/Stat184-Spring2025/Sec1_FP_Shania_Sree_Lauren/refs/heads/main/2018.csv")
#View(data_2018)

data_2019 <- read.csv("https://raw.githubusercontent.com/Stat184-Spring2025/Sec1_FP_Shania_Sree_Lauren/refs/heads/main/2019.csv")
#View(data_2019)

```

```{r}
# 2a. Tidy 2015 data
# 2b. Remove standard error column as only appear in 2015 data and no other
# analogs in the other data sets
# 2c. Add in year column so when merge all data sets together, know this data
# came from 2015
data_2015 <- data_2015 |> select(!c(
  "Standard.Error")
  ) |> mutate(
    Year = 2015
  )

```

```{r}
# 3a. Tidy 2016 data
# 3b. Remove confidence interval columns as only appear in 2016 data and no
# other analogs in the other data sets
# 3c. Add in year column so when merge all data sets together, know this data
# came from 2016
data_2016 <- data_2016 |> select(!c(
    "Lower.Confidence.Interval",
    "Upper.Confidence.Interval"
    )
  ) |> mutate(
    Year = 2016
  )

```

```{r}
# 4a. Tidy 2017 data
# 4b. Remove whisker columns as only appear in 2017 data and no other analogs
# in the other data sets
# 4c. Add in year column so when merge all data sets together, know this data
# came from 2017
data_2017 <- data_2017 |> select(!c(
    "Whisker.high",
    "Whisker.low",
    )
  ) |> mutate(
    Year = 2017
  )

```

```{r}
# 5a. Tidy 2018 data
# 5b. Rename columns in 2018 data so match with names of columns in 2015,
# 2016, and 2017 data
# 5c. Ensure government corruption treated as numeric, since numeric in all
# other data sets
# 5c. Add in year column so when merge all data sets together, know this data
# came from 2018
data_2018 <- data_2018 |> rename(
    Happiness.Rank = Overall.rank,
    Country = Country.or.region,
    Happiness.Score = Score,
    Economy..GDP.per.Capita. = GDP.per.capita,
    Family = Social.support,
    Health..Life.Expectancy. = Healthy.life.expectancy,
    Freedom = Freedom.to.make.life.choices,
    Trust..Government.Corruption. = Perceptions.of.corruption
  ) |> mutate(
    Trust..Government.Corruption. = as.numeric(Trust..Government.Corruption.)
  ) |> mutate(
    Year = 2018
  )

```

```{r}
# 6a. Tidy 2019 data
# 6b. Rename columns in 2019 data so match with names of columns in 2015,
# 2016, 2017, and 2018 data
# 6c. Add in year column so when merge all data sets together, know this data
# came from 2019
data_2019 <- data_2019 |> rename(
    Happiness.Rank = Overall.rank,
    Country = Country.or.region,
    Happiness.Score = Score,
    Economy..GDP.per.Capita. = GDP.per.capita,
    Family = Social.support,
    Health..Life.Expectancy. = Healthy.life.expectancy,
    Freedom = Freedom.to.make.life.choices,
    Trust..Government.Corruption. = Perceptions.of.corruption
  ) |> mutate(
    Year = 2019
  )

```

```{r}
# 7a. Merge all tidied year data by adding the rows of each data set into a
# total years data frame
total_data <- bind_rows(data_2015, data_2016, data_2017, data_2018, data_2019)

```

```{r}
# 8a. Scrap region information for 2017, 2018, and 2019 from the 2015 and
# 2016 data. (If the region is not listed in 2015/2016 or the country was not
# surveyed then, the information was left as null)
# 8b. Merge total years data with 2015 data by matching Country column
# 8c. Add Region column to total data merged with data from 2015. First, add
# regions already known for countries in 2015 and 2016. Then, add in regions
# for the countries  in other years that match the countries from the 2015
# data set.
# 8d. Merge total years data with 2016 data by matching Country column
# 8e. Add Region column to total data merged with data from 2016. First, add
# regions already known for countries in 2015 and 2016. Then, add in regions
# for the countries  in other years that match the countries from the 2016
# data set.
# 8f. Add new region data to final total data set
total_data_merge <- total_data |> left_join(
    x = total_data,
    y = data_2015,
    by = join_by(Country == Country)
  )

total_data_merge$Region = total_data_merge$Region.x
total_data_merge$Region[!is.na(total_data_merge$Region.y)] = total_data_merge$Region.y[!is.na(total_data_merge$Region.y)]

total_data_merge <- total_data_merge |> left_join(
    x = total_data_merge,
    y = data_2016,
    by = join_by(Country == Country)
  )

total_data_merge$Region = total_data_merge$Region.x
total_data_merge$Region[!is.na(total_data_merge$Region.y)] = total_data_merge$Region.y[!is.na(total_data_merge$Region.y)]
total_data$Region <- total_data_merge$Region

```

```{r}
# 9a. Tidy final total data set
# 9b. Rename Family column to support system as this encompasses family and
# friends as social support
total_data <- total_data |>
  rename(
    Support.System = Family
  )
#View(total_data)

```

```{r}
# 10a. Create a summary table based on each feature in the data set
# 10b. Summarize across the numeric columns in the total data set
# 10c. Get the measures of count, min, median, mean, max, and standard
# deviation for each column, allowing for NA values.
# 10d. Pivot longer so the case is a specific measure for each column
# 10e. Separate wider so the column name and measure each have their own
# column
# 10f. Pivot wider so each measure becomes a new column
total_data_summary <- total_data |>
  summarise(across(
    Happiness.Rank:Dystopia.Residual,
    list(
      count = length,
      min = ~min(., na.rm = TRUE),
      median = ~median(., na.rm = TRUE),
      mean = ~mean(., na.rm = TRUE),
      max = ~max(., na.rm = TRUE),
      sd = ~sd(., na.rm = TRUE)
      )
    )
  ) |> pivot_longer(
    cols = Happiness.Rank_count:Dystopia.Residual_sd,
    names_to = "Column_Measure",
    values_to = "Value"
  ) |> separate_wider_delim(
    cols = Column_Measure,
    delim = "_",
    names = c("Column", "Measure")
  ) |> pivot_wider(
    names_from = Measure,
    values_from = Value
  )
```

```{r}
# 11a. Create a summary table with a caption and kable styling.
total_data_summary |>
  kable(
    caption = "Summary Statistics of each Feature in the World Happiness Index data set",
    booktabs = TRUE,
    align = c("l", rep("c", 6))
  ) |> kableExtra::kable_styling(
    bootstrap_options = c("striped", "condensed"),
    font_size = 8
  )
```

```{r}
# 12a. Create a summary table grouped by region for each feature in the data
# set
# 12b. Summarize across the numeric columns in the total data set
# 12c. Get the measures of count, min, median, mean, max, and standard
# deviation for each column, allowing for NA values.
# 12d. Pivot longer so the case is a specific measure for each column
# 12e. Separate wider so the column name and measure each have their own
# column
# 12f. Pivot wider so each measure becomes a new column
# 12g. Remove any NA's in the data set as those are countries whose region we
# don't know and therefore can remove in this region based table.
total_data_summary_region <- total_data |>
  group_by(Region) |>
  summarise(across(
    Happiness.Rank:Dystopia.Residual,
    list(
      count = length,
      min = ~min(., na.rm = TRUE),
      median = ~median(., na.rm = TRUE),
      mean = ~mean(., na.rm = TRUE),
      max = ~max(., na.rm = TRUE),
      sd = ~sd(., na.rm = TRUE)
      )
    )
  ) |> pivot_longer(
    cols = Happiness.Rank_count:Dystopia.Residual_sd,
    names_to = "Column_Measure",
    values_to = "Value"
  ) |> separate_wider_delim(
    cols = Column_Measure,
    delim = "_",
    names = c("Column", "Measure")
  ) |> pivot_wider(
    names_from = Measure,
    values_from = Value
  ) |> drop_na()
```

```{r}
# 13a. Create a summary table with a caption and kable styling.
total_data_summary_region |>
  kable(
    caption = "Summary Statistics of each Region in the World Happiness Index data set",
    booktabs = TRUE,
    align = c("l", rep("c", 6))
  ) |> kableExtra::kable_styling(
    bootstrap_options = c("striped", "condensed"),
    font_size = 5
  )
```


```{r}
# Goal: Tidy the world bank data so only the years and countries included in
# the world happiness index remain. Also, subset the variables to only
# include country, year, and our selected features (access to electricity,
# individuals using the internet, and birth rate). The resulting case is the
# information for a country in a specific year. Then complete EDA analysis by
# creating summary tables of each feature and a scatter plot of happiness
# score v percentage of individuals using the internet.

# Need: the data from the world bank data set

# Plan
# 1a. Read in the world bank data set from our github repository
# 2a. Tidy world bank data
# 2b. Isolate the Year in the date measurement, by splitting the date column
# by the dash delimiter into Year, Month, Day. We only care about the year,
# because all of the measurements were taken on January 1st of each year.
# 2c. Filter the year column by the years of our world happiness index data
# set (2015, 2016, 2017, 2018, and 2019)
# 2d. Filter the country column by the countries in the world happiness index
# data set
# 2e. Select the columns we want to keep from the data set: year, country,
# access to electricity, individuals using internet, and birth rate
# 2f. Rename the access to electricity, individuals using internet, and birth
# rate columns
# 3a. Create a summary table for access to electricity, individuals using
# internet and birth rate in the data set.
# 3b. Summarize across the columns in the total data set
# 3c. Get the measures of count, min, median, mean, max, and standard
# deviation for each column, allowing for NA values.
# 3d. Pivot longer so the case is a specific measure for each column
# 3e. Separate wider so the column name and measure each have their own
# column
# 3f. Pivot wider so each measure becomes a new column
# 4a. Create a summary table with a caption and kable styling.
# 5a. Merge world happiness index data and world bank data
# 5b. Ensure year column in world bank data is treated as numeric, as using
# as one of the columns to join the table on
# 5c. Use a left join on the world happiness index data and the world bank
# data, using the columns country and year. Remove rows where there is no
# data for individuals using internet, as what we are making a graph of.
# 6a. Create a scatter plot of percentage of individuals using the internet
# versus the country's happiness score.
# 6b. Set the x and y axis, the geometry of each mark, point, create labels,
# and add black and white theme

# 1a. Read in the world bank data set from our github repository
world_bank_data <- read.csv("https://raw.githubusercontent.com/Stat184-Spring2025/Sec1_FP_Shania_Sree_Lauren/refs/heads/main/world_bank_development_indicators.csv")
#View(world_bank_data)
```

```{r}
# 2a. Tidy world bank data
# 2b. Isolate the Year in the date measurement, by splitting the date column
# by the dash delimiter into Year, Month, Day. We only care about the year,
# because all of the measurements were taken on January 1st of each year.
# 2c. Filter the year column by the years of our world happiness index data
# set (2015, 2016, 2017, 2018, and 2019)
# 2d. Filter the country column by the countries in the world happiness index
# data set
# 2e. Select the columns we want to keep from the data set: year, country,
# access to electricity, individuals using internet, and birth rate
# 2f. Rename the access to electricity, individuals using internet, and birth
# rate columns
total_data_country <- total_data$Country
world_bank_tidy <- world_bank_data |>
  separate_wider_delim(
    cols = date,
    delim = "-",
    names = c("Year", "Month", "Day")
  ) |> filter(
    (Year %in% c(2015, 2016, 2017, 2018, 2019))
  ) |> filter(
    (country %in% c(total_data_country))
  ) |> select(
    c(country, Year, access_to_electricity., individuals_using_internet., birth_rate)
  ) |> rename(
    access.to.electricity = access_to_electricity.,
    individuals.using.internet = individuals_using_internet.,
    birth.rate = birth_rate
  )

```

```{r}
# 3a. Create a summary table for access to electricity, individuals using
# internet and birth rate in the data set.
# 3b. Summarize across the columns in the total data set
# 3c. Get the measures of count, min, median, mean, max, and standard
# deviation for each column, allowing for NA values.
# 3d. Pivot longer so the case is a specific measure for each column
# 3e. Separate wider so the column name and measure each have their own
# column
# 3f. Pivot wider so each measure becomes a new column
world_bank_summary <- world_bank_tidy |>
  summarise(across(
    access.to.electricity:birth.rate,
    list(
      count = length,
      min = ~min(., na.rm = TRUE),
      median = ~median(., na.rm = TRUE),
      mean = ~mean(., na.rm = TRUE),
      max = ~max(., na.rm = TRUE),
      sd = ~sd(., na.rm = TRUE)
      )
    )
  ) |> pivot_longer(
    cols = access.to.electricity_count:birth.rate_sd,
    names_to = "Column_Measure",
    values_to = "Value"
  ) |> separate_wider_delim(
    cols = Column_Measure,
    delim = "_",
    names = c("Column", "Measure")
  ) |> pivot_wider(
    names_from = Measure,
    values_from = Value
  )

```

```{r}
# 4a. Create a summary table with a caption and kable styling.
world_bank_summary |>
  kable(
    caption = "Summary Statistics of each Feature in the World Bank data set",
    booktabs = TRUE,
    align = c("l", rep("c", 6))
  ) |> kableExtra::kable_styling(
    bootstrap_options = c("striped", "condensed"),
    font_size = 8
  )
```
```{r}
# 5a. Merge world happiness index data and world bank data
# 5b. Ensure year column in world bank data is treated as numeric, as using
# as one of the columns to join the table on
# 5c. Use a left join on the world happiness index data and the world bank
# data, using the columns country and year. Remove rows where there is no
# data for individuals using internet, as what we are making a graph of.
world_bank_tidy <- world_bank_tidy |>
  mutate(
    Year = as.numeric(Year)
  )

merged_data <- total_data |>
  left_join(
    x = total_data,
    y = world_bank_tidy,
    by = join_by(Country == country, Year == Year)
  ) |> drop_na(individuals.using.internet)

```

```{r}
# 6a. Create a scatter plot of percentage of individuals using the internet
# versus the country's happiness score.
# 6b. Set the x and y axis, the geometry of each mark, point, create labels,
# and add black and white theme
ggplot(
  data = merged_data,
  mapping = aes(
    x = individuals.using.internet,
    y = Happiness.Score
  )
) + geom_point() + labs(
  x = "Percentage of Individuals Using the Internet",
  y = "Happiness Score",
  title = "Happiness Score v Percentage of Individuals Using the Internet"
) + theme_bw()

```

```{r}
# Goal: Create a frequency table of the binned happiness scores against each
# region. The scores should be binned, as they are currently in decimal form,
# therefore generalizing them will allow for greater comparison power.

# Need: tidied world happiness index data

# Plan
# 1a. Reform world happiness index data so it can be used to create a
# frequency table
# 1b. Bin the happiness score in the world happiness index data (going by 0.5
# stop inclusive, from 0 - 10)
# 1c. Drop any rows in the data set where the country region is unknown, as
# meant to be comparing across regions
# 2a. Create region and happiness score world happiness index relative
# frequency table
# 2b. Call tabyl function with region as row and happiness score as column
# 2e. Add marginal totals
# 2f. Add percentages
# 2g. Set decimals to two places
# 2h. Add row and column titles
# 3a. Polish region and happiness score relative frequency table
# 3b. Put percentages for each cell in parentheses
# 3c. Add commas to numbers over nine hundred and ninety nine
# 3d. Add counts
# 3e. Add title and kableExtra for styling

# 1a. Reform world happiness index data so it can be used to create a
# frequency table
# 1b. Bin the happiness score in the world happiness index data (going by 0.5
# stop inclusive, from 0 - 10)
# 1c. Drop any rows in the data set where the country region is unknown, as
# meant to be comparing across regions 
total_data_summary_region <- total_data |> mutate(
  binned.happiness.score = case_when(
    Happiness.Score <= 0.5 ~ "0 - 0.5",
    Happiness.Score > 0.5 & Happiness.Score <= 1 ~ "0.5 - 1",
    Happiness.Score > 1 & Happiness.Score <= 1.5 ~ "1 - 1.5",
    Happiness.Score > 1.5 & Happiness.Score <= 2 ~ "1.5 - 2",
    Happiness.Score > 2 & Happiness.Score <= 2.5 ~ "2 - 2.5",
    Happiness.Score > 2.5 & Happiness.Score <= 3 ~ "2.5 - 3",
    Happiness.Score > 3 & Happiness.Score <= 3.5 ~ "3 - 3.5",
    Happiness.Score > 3.5 & Happiness.Score <= 4 ~ "3.5 - 4",
    Happiness.Score > 4 & Happiness.Score <= 4.5 ~ "4 - 4.5",
    Happiness.Score > 4.5 & Happiness.Score <= 5 ~ "4.5 - 5",
    Happiness.Score > 5 & Happiness.Score <= 5.5 ~ "5 - 5.5",
    Happiness.Score > 5.5 & Happiness.Score <= 6 ~ "5.5 - 6",
    Happiness.Score > 6 & Happiness.Score <= 6.5 ~ "6 - 6.5",
    Happiness.Score > 6.5 & Happiness.Score <= 7 ~ "6.5 - 7",
    Happiness.Score > 7 & Happiness.Score <= 7.5 ~ "7 - 7.5",
    Happiness.Score > 7.5 & Happiness.Score <= 8 ~ "7.5 - 8",
    Happiness.Score > 8 & Happiness.Score <= 8.5 ~ "8 - 8.5",
    Happiness.Score > 8.5 & Happiness.Score <= 9 ~ "8.5 - 9",
    Happiness.Score > 9 & Happiness.Score <= 9.5 ~ "9 - 9.5",
    Happiness.Score > 9.5 & Happiness.Score <= 10 ~ "9.5 - 10"
    )
  ) |> drop_na(Region)

```

```{r}
# 2a. Create region and happiness score world happiness index relative
# frequency table
# 2b. Call tabyl function with region as row and happiness score as column
# 2e. Add marginal totals
# 2f. Add percentages
# 2g. Set decimals to two places
# 2h. Add row and column titles
world_happy_freq <- total_data_summary_region |>
  tabyl(
    Region, binned.happiness.score
  ) |> adorn_totals(
    where = c("row", "col")
  ) |> adorn_percentages(
    denominator = "all"
  ) |> adorn_pct_formatting(
    digits = 2
  ) |> adorn_title(
    placement = "combined",
    row_name = "Region",
    col_name = "Happiness Score"
  )

```

```{r}
# 3a. Polish region and happiness score relative frequency table
# 3b. Put percentages for each cell in parentheses
# 3c. Add commas to numbers over nine hundred and ninety nine
# 3d. Add counts
# 3e. Add title and kableExtra for styling
formatNs <-
  attr(
    world_happy_freq, "core"
  ) |> adorn_totals(
    where = c("row", "col")
  ) |> mutate(
    across(where(is.numeric), \(x) format(x, big.mark = ",", na.rm = TRUE))
  )

world_happy_freq <- world_happy_freq |>
  adorn_ns(
    position = "front", ns = formatNs
  )

world_happy_freq |>
  kable(
    caption = "Region and Happiness Score of Countires in the World Happiness Index 2015 - 2019",
    booktabs = TRUE,
    align = c("l", rep("c", 6))
  ) |> kableExtra::kable_styling(
    bootstrap_options = c("striped", "condensed"),
    font_size = 3
  )

```


```{r}
# Goal: Create a scatter plot of the percentage of individuals using the internet versus the country's happiness score. 

# Need: merged data set of world happiness index data and world bank data

# Plan
# 1a. Create a scatter plot of percentage of individuals using the internet
# versus the country's happiness score.
# 1b. Specify the wrangled data to be used, the x axis, the y
# axis, and what the color of each point is based on, the happiness score
# 1c. Specify aesthetic geometry, point
# 1d. Create a linear trend line with no confidence interval, set the color
# to black, and set the line width
# 1e. Add labels to the x axis, y axis, color, and the title, add black and
# white theme

# 1a. Create a scatter plot of percentage of individuals using the internet
# versus the country's happiness score.
# 1b. Specify the wrangled data to be used, the x axis, the y
# axis, and what the color of each point is based on, the happiness score
# 1c. Specify aesthetic geometry, point
# 1d. Create a linear trend line with no confidence interval, set the color
# to black, and set the line width
# 1e. Add labels to the x axis, y axis, color, and the title, add black and
# white theme
ggplot(
  data = merged_data,
  mapping = aes(
    x = individuals.using.internet,
    y = Happiness.Score,
    color = Happiness.Score
  )
) + geom_point(
  size = 2
) + geom_smooth(
  method = lm,
  se = FALSE,
  col = '#000000',
  linewidth = 2
) + labs(
  x = "Percentage of Individuals Using the Internet",
  y = "Happiness Score",
  color = "Happiness Score",
  title = "Happiness Score v Percentage of Individuals Using the Internet"
) + theme_bw()

```
