---
title: "Final Project"
subtitle: "Stat 184"
author: "Shania, Sree, and Lauren"
date: "May 7, 2025"
date-modified: now
format:
  pdf:
    toc: false
    code-fold: true
    code-link: true
    number-sections: true
    number-depth: 5
    fig-align: center
    cap-location: top
    geometry: 
      - top = 1in
      - left = 1in
      - right = 1in
      - bottom = 1in
    colorlinks: true
execute: 
  echo: false
  output: true
  warning: false
code-appendix: true
---
## Introduction

The World Happiness Report is a landmark global survey that measures and ranks the happiness levels of nations, providing valuable insights into the well-being of populations worldwide. By analyzing factors such as GDP per capita, birth rate, freedom, people with access to resources like the internet, and perceptions of corruption, the report offers a comprehensive understanding of what contributes to a fulfilling life. Happiness, as a metric, goes beyond economic indicators to encompass emotional and social dimensions, making it a crucial tool for policymakers and researchers. However, happiness is a multifaceted concept that cannot be fully captured by a single measure, requiring a deeper examinations of cultural, environmental, and individual factors to truly understand what makes societies thrive and happy.

In this project, we aim to explore two core research questions:

1.  Does time have an effect on the happiness rate? (i.e. do the "happiest" countries tend to stay happy even after a certain number of years and do the "saddest" countries tend to stay sad even after a certain number of years?).
2.  How does the birth rate in the data set correlate with its reported happiness levels? Are there any underlying socioeconomic factors that might explain the relationship?

These questions explore gaps in how happiness persists over time and connects to demographic shifts like birth rates. The findings could inform policy decisions, highlighting the role of stability and population dynamics in well-being. The project aims to provide actionable insights that deepen the understanding of global happiness patterns.

## Data Provenance

For the purpose of this project, we used two datasets to explore the happiness rates across regions and also to explore the factors that could've had an impact on the happiness of the regions such as GDP. These datasets were found via reliable sources online and have gone through rigorous wrangling and tidying to result in a trustworthy final dataset for this project.

#### Primary Dataset

-   Source: Kaggle

-   Description: This dataset contains happiness rankings and scores for over 150 countries from the years of 2015 to 2019 with metrics such as GDP per capita, social support, birth rate, freedom and corruption. It includes approximately over 150 rows which represent the countries and over 10 columns that represent the factors related to these countries.

-   Purpose: This dataset is used to analyze the global well-being trends, to quantify drivers of happiness, and to provide evidence-based insights.

-   Cases: Each row represents a country, with the columns giving details about its happiness score and other contributing factors.

#### Secondary Dataset

-   Source: Kaggle

-   Description: This dataset contains information about factors such as economic, social, political, and environmental indicators for approximately over 260 countries from the years of 1960 to 2022. It has approximately 268 rows which represents the countries and 48 columns with numerical values for factors including GDP, birth rates, energy consumption, etc.

-   Purpose: This secondary dataset is used to provide additional supprt to our initial goal of analyzing the global factors that can have an impact on a regions happiness score.

-   Cases: Each row represents a country, with the columns giving economic, social, environmental, and governance details about the region.

#### Data Wrangling

To help us answer our research questions, we integrated the data from the primary and secondary datasets into a single dataset.

**Merging:**

-   The datasets were merged using the countries from both the primary and secondary datasets.

-   By merging the datasets, we filtered out countries absent in the primary datatset, streamlining comparisons across regions present in both datasets.

**Variable Selection:**

-   We retained variables that will be necessary for answering our research questions such as the GDP of the country, birth rate, happiness score, etc.

-   Unnecessary columns such as rule of law, agricultural land percent, forest land percent, etc. have been dropped to make the datasets more clear and concise.

**Filtering and Cleaning:**

-   Columns that were missing information in the secondary dataset were excluded to ensure that there was no bias within countries by excluding certain factors for some and including those influential factors for other regions.


### FAIR AND CARE Principles:

The datasets used in this report adhere to the FAIR principles, highlighting the availability of the data:

**F- FINDABLE:**
- Both the primary and secondary datasets can be found on Kaggle, which is a platform where people can find and publish datasets in a clear location
**A- ACCESSIBLE:**
- Both datasets are accessible through Kaggle, allowing anyone to download and use the data at their leisure.
**I- INTEROPERABLE:**
- Both datasets are in the form of .csv files, making the data compatible with many tools and platforms like R-Studio. 
**R- REUSABLE:**
- Both datasets include metadata and documentation that supports this
- Through our data wrangling process, we changed the column name referring to family/social to social support. We also accounted for any data not measured as null. By doing so, we cleaned up the structure making it easier for future use

Considering that neither dataset includes any sensitive or personal data, we still highlighted ethical practices throughout our project. Both datasets are publicly available and our analysis and primary questions asked do not hurt any individuals.  
### Exploratory Data Analysis (EDA)

To uncover patterns in global well-being and address our research question, we conducted a comprehensive Exploratory Data Analysis (WDA) on both the World Happiness Index and World Bank datasets. This involved generating summary statistics and examining distributions of key variables across regions and development indicators. 

```{r}
# Import all necessary libraries for the entire qmd file 
library(dplyr)
library(tidyr)
library(knitr)
library(kableExtra)
library(ggplot2)
library(janitor)
```

### World Happiness Index Data Wrangling and EDA

Table 1 provides the summary statistics for the Happiness Index dataset, highlighting central tendencies and variability across nine key metrics. 
```{r}
## World Happiness Index Data Wrangling and EDA


# Goal: Tidy the world happiness data so each year is integrated into one
# dataset. The resulting case is the happiness score for a country in a
# specific year. Then complete EDA analysis by creating summary tables of
# each feature and grouped by region. 

# Need: all of the separate world happiness data csv (2015, 2016, 2017, 2018,
# and 2019)

# Plan
# 1a. Read in all of the individual data sets (2015, 2016, 2017, 2018, and
# 2019) from our github repository
# 2a. Tidy 2015 data
# 2b. Remove standard error column as only appear in 2015 data and no other
# analogs in the other data sets
# 2c. Add in year column so when merge all data sets together, know this data
# came from 2015
# 3a. Tidy 2016 data
# 3b. Remove confidence interval columns as only appear in 2016 data and no
# other analogs in the other data sets
# 3c. Add in year column so when merge all data sets together, know this data
# came from 2016
# 4a. Tidy 2017 data
# 4b. Remove whisker columns as only appear in 2017 data and no other analogs
# in the other data sets
# 4c. Add in year column so when merge all data sets together, know this data
# came from 2017
# 5a. Tidy 2018 data
# 5b. Rename columns in 2018 data so match with names of columns in 2015,
# 2016, and 2017 data
# 5c. Ensure government corruption treated as numeric, since numeric in all
# other data sets
# 5c. Add in year column so when merge all data sets together, know this data
# came from 2018
# 6a. Tidy 2019 data
# 6b. Rename columns in 2019 data so match with names of columns in 2015,
# 2016, 2017, and 2018 data
# 6c. Add in year column so when merge all data sets together, know this data
# came from 2019
# 7a. Merge all tidied year data by adding the rows of each data set into a
# total years data frame
# 8a. Scrap region information for 2017, 2018, and 2019 from the 2015 and
# 2016 data. (If the region is not listed in 2015/2016 or the country was not
# surveyed then, the information was left as null)
# 8b. Merge total years data with 2015 data by matching Country column
# 8c. Add Region column to total data merged with data from 2015. First, add
# regions already known for countries in 2015 and 2016. Then, add in regions
# for the countries  in other years that match the countries from the 2015
# data set.
# 8d. Merge total years data with 2016 data by matching Country column
# 8e. Add Region column to total data merged with data from 2016. First, add
# regions already known for countries in 2015 and 2016. Then, add in regions
# for the countries  in other years that match the countries from the 2016
# data set.
# 8f. Add new region data to final total data set
# 9a. Tidy final total data set
# 9b. Rename Family column to support system as this encompasses family and
# friends as social support
# 10a. Create a summary table based on each feature in the data set
# 10b. Summarize across the numeric columns in the total data set
# 10c. Get the measures of count, min, median, mean, max, and standard
# deviation for each column, allowing for NA values.
# 10d. Pivot longer so the case is a specific measure for each column
# 10e. Separate wider so the column name and measure each have their own
# column
# 10f. Pivot wider so each measure becomes a new column
# 11a. Create a summary table with a caption and kable styling.
# 12a. Create a summary table grouped by region for each feature in the data
# set
# 12b. Summarize across the numeric columns in the total data set
# 12c. Get the measures of count, min, median, mean, max, and standard
# deviation for each column, allowing for NA values.
# 12d. Pivot longer so the case is a specific measure for each column
# 12e. Separate wider so the column name and measure each have their own
# column
# 12f. Pivot wider so each measure becomes a new column
# 12g. Remove any NA's in the data set as those are countries whose region we
# don't know and therefore can remove in this region based table.
# 13a. Create a summary table with a caption and kable styling.
data_2015 <- read.csv("https://raw.githubusercontent.com/Stat184-Spring2025/Sec1_FP_Shania_Sree_Lauren/refs/heads/main/2015.csv")
#View(data_2015)

data_2016 <- read.csv("https://raw.githubusercontent.com/Stat184-Spring2025/Sec1_FP_Shania_Sree_Lauren/refs/heads/main/2016.csv")
#View(data_2016)

data_2017 <- read.csv("https://raw.githubusercontent.com/Stat184-Spring2025/Sec1_FP_Shania_Sree_Lauren/refs/heads/main/2017.csv")
#View(data_2017)

data_2018 <- read.csv("https://raw.githubusercontent.com/Stat184-Spring2025/Sec1_FP_Shania_Sree_Lauren/refs/heads/main/2018.csv")
#View(data_2018)

data_2019 <- read.csv("https://raw.githubusercontent.com/Stat184-Spring2025/Sec1_FP_Shania_Sree_Lauren/refs/heads/main/2019.csv")
#View(data_2019)

```

```{r}
# 2a. Tidy 2015 data
# 2b. Remove standard error column as only appear in 2015 data and no other
# analogs in the other data sets
# 2c. Add in year column so when merge all data sets together, know this data
# came from 2015
data_2015 <- data_2015 |>
  select(!c(
    "Standard.Error")
  ) |> mutate(
    Year = 2015
  )

```

```{r}
# 3a. Tidy 2016 data
# 3b. Remove confidence interval columns as only appear in 2016 data and no
# other analogs in the other data sets
# 3c. Add in year column so when merge all data sets together, know this data
# came from 2016
data_2016 <- data_2016 |>
  select(!c(
    "Lower.Confidence.Interval",
    "Upper.Confidence.Interval"
    )
  ) |> mutate(
    Year = 2016
  )

```

```{r}
# 4a. Tidy 2017 data
# 4b. Remove whisker columns as only appear in 2017 data and no other analogs
# in the other data sets
# 4c. Add in year column so when merge all data sets together, know this data
# came from 2017
data_2017 <- data_2017 |>
  select(!c(
    "Whisker.high",
    "Whisker.low",
    )
  ) |> mutate(
    Year = 2017
  )

```

```{r}
# 5a. Tidy 2018 data
# 5b. Rename columns in 2018 data so match with names of columns in 2015,
# 2016, and 2017 data
# 5c. Ensure government corruption treated as numeric, since numeric in all
# other data sets
# 5c. Add in year column so when merge all data sets together, know this data
# came from 2018
data_2018 <- data_2018 |> rename(
    Happiness.Rank = Overall.rank,
    Country = Country.or.region,
    Happiness.Score = Score,
    Economy..GDP.per.Capita. = GDP.per.capita,
    Family = Social.support,
    Health..Life.Expectancy. = Healthy.life.expectancy,
    Freedom = Freedom.to.make.life.choices,
    Trust..Government.Corruption. = Perceptions.of.corruption
  ) |> mutate(
    Trust..Government.Corruption. = as.numeric(Trust..Government.Corruption.)
  ) |> mutate(
    Year = 2018
  )

```

```{r}
# 6a. Tidy 2019 data
# 6b. Rename columns in 2019 data so match with names of columns in 2015,
# 2016, 2017, and 2018 data
# 6c. Add in year column so when merge all data sets together, know this data
# came from 2019
data_2019 <- data_2019 |> rename(
    Happiness.Rank = Overall.rank,
    Country = Country.or.region,
    Happiness.Score = Score,
    Economy..GDP.per.Capita. = GDP.per.capita,
    Family = Social.support,
    Health..Life.Expectancy. = Healthy.life.expectancy,
    Freedom = Freedom.to.make.life.choices,
    Trust..Government.Corruption. = Perceptions.of.corruption
  ) |> mutate(
    Year = 2019
  )

```

```{r}
# 7a. Merge all tidied year data by adding the rows of each data set into a
# total years data frame
total_data <- bind_rows(data_2015, data_2016, data_2017, data_2018, data_2019)

```

```{r}
# 8a. Scrap region information for 2017, 2018, and 2019 from the 2015 and
# 2016 data. (If the region is not listed in 2015/2016 or the country was not
# surveyed then, the information was left as null)
# 8b. Merge total years data with 2015 data by matching Country column
# 8c. Add Region column to total data merged with data from 2015. First, add
# regions already known for countries in 2015 and 2016. Then, add in regions
# for the countries  in other years that match the countries from the 2015
# data set.
# 8d. Merge total years data with 2016 data by matching Country column
# 8e. Add Region column to total data merged with data from 2016. First, add
# regions already known for countries in 2015 and 2016. Then, add in regions
# for the countries  in other years that match the countries from the 2016
# data set.
# 8f. Add new region data to final total data set
total_data_merge <- total_data |> left_join(
    x = total_data,
    y = data_2015,
    by = join_by(Country == Country)
  )

total_data_merge$Region = total_data_merge$Region.x
total_data_merge$Region[!is.na(total_data_merge$Region.y)] =
  total_data_merge$Region.y[!is.na(total_data_merge$Region.y)]

total_data_merge <- total_data_merge |> left_join(
    x = total_data_merge,
    y = data_2016,
    by = join_by(Country == Country)
  )

total_data_merge$Region = total_data_merge$Region.x
total_data_merge$Region[!is.na(total_data_merge$Region.y)] =
  total_data_merge$Region.y[!is.na(total_data_merge$Region.y)]
total_data$Region <- total_data_merge$Region

```

```{r}
# 9a. Tidy final total data set
# 9b. Rename Family column to support system as this encompasses family and
# friends as social support
total_data <- total_data |>
  rename(
    Support.System = Family
  )
#View(total_data)

```

```{r}
# 10a. Create a summary table based on each feature in the data set
# 10b. Summarize across the numeric columns in the total data set
# 10c. Get the measures of count, min, median, mean, max, and standard
# deviation for each column, allowing for NA values.
# 10d. Pivot longer so the case is a specific measure for each column
# 10e. Separate wider so the column name and measure each have their own
# column
# 10f. Pivot wider so each measure becomes a new column
total_data_summary <- total_data |>
  summarise(across(
    Happiness.Rank:Dystopia.Residual,
    list(
      count = length,
      min = ~min(., na.rm = TRUE),
      median = ~median(., na.rm = TRUE),
      mean = ~mean(., na.rm = TRUE),
      max = ~max(., na.rm = TRUE),
      sd = ~sd(., na.rm = TRUE)
      )
    )
  ) |> pivot_longer(
    cols = Happiness.Rank_count:Dystopia.Residual_sd,
    names_to = "Column_Measure",
    values_to = "Value"
  ) |> separate_wider_delim(
    cols = Column_Measure,
    delim = "_",
    names = c("Column", "Measure")
  ) |> pivot_wider(
    names_from = Measure,
    values_from = Value
  )
```

```{r}
#| label: tbl-summaryvariablesworldhappiness
#| tbl-cap: "Summary Statistics for each variable in the World Happiness Index Data"
#| tbl-pos: H
#| lst-label: lst-table1
#| lst-cap: "Code Chunk for Making World Happiness Summary Stats Enlisted"
# 11a. Create a summary table with a caption and kable styling.
total_data_summary |>
  kable(
    caption = "Summary Statistics of each Feature in the World Happiness Index data set",
    booktabs = TRUE,
    align = c("l", rep("c", 6))
  ) |> kableExtra::kable_styling(
    bootstrap_options = c("striped", "condensed"),
    font_size = 8
  )
```
**Key Insights:**

Happiness scores range widely (2.69-7.77), with a mean of 5.38 (~1.13 SD).

GDP and life expectancy show right-skewed distributions (mean < median). 

Government trust scores are notably low (mean 0.13, max 0.55). 

In @tbl-summaryvariablesworldhappiness



### World Bank Data Wrangling and EDA

Table 2 summarizes 720 observations of critical development metrics like a country's birth rate, access to electricity and internet:

```{r}
## World Bank Data Wrangling and EDA


# Goal: Tidy the world bank data so only the years and countries included in
# the world happiness index remain. Also, subset the variables to only
# include country, year, and our selected features (access to electricity,
# individuals using the internet, and birth rate). The resulting case is the
# information for a country in a specific year. Then complete EDA analysis by
# creating summary tables of each feature and scatter plots of happiness
# score v percentage of individuals using the internet, birth rate, and
# access to electricity.

# Need: the data from the world bank data set

# Plan
# 1a. Read in the world bank data set from our github repository
# 2a. Tidy world bank data
# 2b. Isolate the Year in the date measurement, by splitting the date column
# by the dash delimiter into Year, Month, Day. We only care about the year,
# because all of the measurements were taken on January 1st of each year.
# 2c. Filter the year column by the years of our world happiness index data
# set (2015, 2016, 2017, 2018, and 2019)
# 2d. Filter the country column by the countries in the world happiness index
# data set
# 2e. Select the columns we want to keep from the data set: year, country,
# access to electricity, individuals using internet, and birth rate
# 2f. Rename the access to electricity, individuals using internet, and birth
# rate columns
# 3a. Create a summary table for access to electricity, individuals using
# internet and birth rate in the data set.
# 3b. Summarize across the columns in the total data set
# 3c. Get the measures of count, min, median, mean, max, and standard
# deviation for each column, allowing for NA values.
# 3d. Pivot longer so the case is a specific measure for each column
# 3e. Separate wider so the column name and measure each have their own
# column
# 3f. Pivot wider so each measure becomes a new column
# 4a. Create a summary table with a caption and kable styling.
# 5a. Merge world happiness index data and world bank data
# 5b. Ensure year column in world bank data is treated as numeric, as using
# as one of the columns to join the table on
# 5c. Use a left join on the world happiness index data and the world bank
# data, using the columns country and year. Remove rows where there is no
# data for individuals using internet, birth rate, and access to electricity
# 6a. Create a scatter plot of percentage of individuals using the internet
# versus the country's happiness score.
# 6b. Set the x and y axis, the geometry of each mark, point, create labels,
# and add black and white theme
# 7a. Create a scatter plot of the birth rate versus the country's happiness
# score.
# 7b. Set the x and y axis, the geometry of each mark, point, create labels,
# and add black and white theme
# 8a. Create a scatter plot of access to electricity versus the country's
# happiness score.
# 8b. Set the x and y axis, the geometry of each mark, point, create labels,
# and add black and white theme

# 1a. Read in the world bank data set from our github repository
world_bank_data <- read.csv("https://raw.githubusercontent.com/Stat184-Spring2025/Sec1_FP_Shania_Sree_Lauren/refs/heads/main/world_bank_development_indicators.csv")
#View(world_bank_data)
```

```{r}
# 2a. Tidy world bank data
# 2b. Isolate the Year in the date measurement, by splitting the date column
# by the dash delimiter into Year, Month, Day. We only care about the year,
# because all of the measurements were taken on January 1st of each year.
# 2c. Filter the year column by the years of our world happiness index data
# set (2015, 2016, 2017, 2018, and 2019)
# 2d. Filter the country column by the countries in the world happiness index
# data set
# 2e. Select the columns we want to keep from the data set: year, country,
# access to electricity, individuals using internet, and birth rate
# 2f. Rename the access to electricity, individuals using internet, and birth
# rate columns
total_data_country <- total_data$Country
world_bank_tidy <- world_bank_data |>
  separate_wider_delim(
    cols = date,
    delim = "-",
    names = c("Year", "Month", "Day")
  ) |> filter(
    (Year %in% c(2015, 2016, 2017, 2018, 2019))
  ) |> filter(
    (country %in% c(total_data_country))
  ) |> select(
    c(country, Year, access_to_electricity., individuals_using_internet., birth_rate)
  ) |> rename(
    access.to.electricity = access_to_electricity.,
    individuals.using.internet = individuals_using_internet.,
    birth.rate = birth_rate
  )

```

```{r}
# 3a. Create a summary table for access to electricity, individuals using
# internet and birth rate in the data set.
# 3b. Summarize across the columns in the total data set
# 3c. Get the measures of count, min, median, mean, max, and standard
# deviation for each column, allowing for NA values.
# 3d. Pivot longer so the case is a specific measure for each column
# 3e. Separate wider so the column name and measure each have their own
# column
# 3f. Pivot wider so each measure becomes a new column
world_bank_summary <- world_bank_tidy |>
  summarise(across(
    access.to.electricity:birth.rate,
    list(
      count = length,
      min = ~min(., na.rm = TRUE),
      median = ~median(., na.rm = TRUE),
      mean = ~mean(., na.rm = TRUE),
      max = ~max(., na.rm = TRUE),
      sd = ~sd(., na.rm = TRUE)
      )
    )
  ) |> pivot_longer(
    cols = access.to.electricity_count:birth.rate_sd,
    names_to = "Column_Measure",
    values_to = "Value"
  ) |> separate_wider_delim(
    cols = Column_Measure,
    delim = "_",
    names = c("Column", "Measure")
  ) |> pivot_wider(
    names_from = Measure,
    values_from = Value
  )

```

```{r}
#| label: tbl-summaryworldbank
#| tbl-cap: "Summary Statistics of each feature from the World Bank data set"
#| tbl-pos: H
#| lst-label: lst-table1
#| lst-cap: "Code Chunk for Making World Bank Summary Table"
# 4a. Create a summary table with a caption and kable styling.
world_bank_summary |>
  kable(
    caption = "Summary Statistics of each Feature in the World Bank data set",
    booktabs = TRUE,
    align = c("l", rep("c", 6))
  ) |> kableExtra::kable_styling(
    bootstrap_options = c("striped", "condensed"),
    font_size = 8
  )
```
**Key Insights:**

Electricity access is bimodal as the median is 99.6% of the countries having access to electricity but the mean is 82.5% due to low access outliers. 

Birth rates vary significantly (a min of 6.4 and a max of 46.6), which suggests demographic transition stages (fluctuation between high ans low birth rates) within countries. 

In @tbl-summaryworldbank

```{r}
# 5a. Merge world happiness index data and world bank data
# 5b. Ensure year column in world bank data is treated as numeric, as using
# as one of the columns to join the table on
# 5c. Use a left join on the world happiness index data and the world bank
# data, using the columns country and year. Remove rows where there is no
# data for individuals using internet, birth rate, and access to electricity 
world_bank_tidy <- world_bank_tidy |>
  mutate(
    Year = as.numeric(Year)
  )

merged_data <- total_data |>
  left_join(
    x = total_data,
    y = world_bank_tidy,
    by = join_by(Country == country, Year == Year)
  ) |> drop_na(c(individuals.using.internet, birth.rate, access.to.electricity))

```

```{r}
#| label: fig-internetplot
#| fig-cap: "Happiness Score versus Percentage of Individuals Using the Internet"
#| fig-pos: H
#| fig-height: 5
#| fig-alt: "Scatterplot of happiness score v internet"
#| lst-cap: "Code Chunk for Making Happiness Score v Internet Figure"
# 6a. Create a scatter plot of percentage of individuals using the internet
# versus the country's happiness score.
# 6b. Set the x and y axis, the geometry of each mark, point, create labels,
# and add black and white theme
ggplot(
  data = merged_data,
  mapping = aes(
    x = individuals.using.internet,
    y = Happiness.Score
  )
) + geom_point() + labs(
  x = "Percentage of Individuals Using the Internet",
  y = "Happiness Score",
  title = "Happiness Score v Percentage of Individuals Using the Internet"
) + theme_bw()

```
In @fig-internetplot

```{r}
#| label: fig-birthrateplot
#| fig-cap: "Happiness Score versus Birth Rate"
#| fig-pos: H
#| fig-height: 5
#| fig-alt: "Scatterplot of happiness score v birth rate"
#| lst-cap: "Code Chunk for Making Happiness Score v birth rate Figure"
# 7a. Create a scatter plot of the birth rate versus the country's happiness
# score.
# 7b. Set the x and y axis, the geometry of each mark, point, create labels,
# and add black and white theme
ggplot(
  data = merged_data,
  mapping = aes(
    x = birth.rate,
    y = Happiness.Score
  )
) + geom_point() + labs(
  x = "Birth Rate",
  y = "Happiness Score",
  title = "Happiness Score v Birth Rate"
) + theme_bw()

```
In @fig-birthrateplot

```{r}
#| label: fig-electricityplot
#| fig-cap: "Happiness Score versus Access to Electricity"
#| fig-pos: H
#| fig-height: 5
#| fig-alt: "Scatterplot of happiness score v electricity"
#| lst-cap: "Code Chunk for Making Happiness Score v eletricity Figure"
# 8a. Create a scatter plot of access to electricity versus the country's
# happiness score.
# 8b. Set the x and y axis, the geometry of each mark, point, create labels,
# and add black and white theme
ggplot(
  data = merged_data,
  mapping = aes(
    x = access.to.electricity,
    y = Happiness.Score
  )
) + geom_point() + labs(
  x = "Access to Electricity",
  y = "Happiness Score",
  title = "Happiness Score v Access to Electricity"
) + theme_bw()


```
In @fig-electricityplot

## Visualization 1 - Frequency Table of Happiness Scores and Region

This table examines the distribution of happiness scores across 10 global regions over a five-year period, categorizing countries into score ranges of 2.5 to 8 to identify patterns. With this data, we can explore the question of whether happiness rankings stay consistent over time.

```{r}
## Visualization 1 - Frequency Table of Happiness Scores and Region


# Goal: Create a frequency table of the binned happiness scores against each
# region. The scores should be binned, as they are currently in decimal form,
# therefore generalizing them will allow for greater comparison power.

# Need: tidied world happiness index data

# Plan
# 1a. Reform world happiness index data so it can be used to create a
# frequency table
# 1b. Bin the happiness score in the World Happiness Index data (going by 0.5
# stop inclusive, from 0 - 10)
# 1c. Drop any rows in the data set where the country region is unknown, as
# meant to be comparing across regions
# 2a. Create region and happiness score world happiness index relative
# frequency table
# 2b. Call tabyl function with region as row and happiness score as column
# 2e. Add marginal totals
# 2f. Add percentages
# 2g. Set decimals to two places
# 2h. Add row and column titles
# 3a. Polish region and happiness score relative frequency table
# 3b. Put percentages for each cell in parentheses
# 3c. Add commas to numbers over nine hundred and ninety nine
# 3d. Add counts
# 3e. Add title and kableExtra for styling

# 1a. Reform world happiness index data so it can be used to create a
# frequency table
# 1b. Bin the happiness score in the world happiness index data (going by 0.5
# stop inclusive, from 0 - 10)
# 1c. Drop any rows in the data set where the country region is unknown, as
# meant to be comparing across regions 
total_data_summary_region <- total_data |> mutate(
  binned.happiness.score = case_when(
    Happiness.Score <= 0.5 ~ "0 - 0.5",
    Happiness.Score > 0.5 & Happiness.Score <= 1 ~ "0.5 - 1",
    Happiness.Score > 1 & Happiness.Score <= 1.5 ~ "1 - 1.5",
    Happiness.Score > 1.5 & Happiness.Score <= 2 ~ "1.5 - 2",
    Happiness.Score > 2 & Happiness.Score <= 2.5 ~ "2 - 2.5",
    Happiness.Score > 2.5 & Happiness.Score <= 3 ~ "2.5 - 3",
    Happiness.Score > 3 & Happiness.Score <= 3.5 ~ "3 - 3.5",
    Happiness.Score > 3.5 & Happiness.Score <= 4 ~ "3.5 - 4",
    Happiness.Score > 4 & Happiness.Score <= 4.5 ~ "4 - 4.5",
    Happiness.Score > 4.5 & Happiness.Score <= 5 ~ "4.5 - 5",
    Happiness.Score > 5 & Happiness.Score <= 5.5 ~ "5 - 5.5",
    Happiness.Score > 5.5 & Happiness.Score <= 6 ~ "5.5 - 6",
    Happiness.Score > 6 & Happiness.Score <= 6.5 ~ "6 - 6.5",
    Happiness.Score > 6.5 & Happiness.Score <= 7 ~ "6.5 - 7",
    Happiness.Score > 7 & Happiness.Score <= 7.5 ~ "7 - 7.5",
    Happiness.Score > 7.5 & Happiness.Score <= 8 ~ "7.5 - 8",
    Happiness.Score > 8 & Happiness.Score <= 8.5 ~ "8 - 8.5",
    Happiness.Score > 8.5 & Happiness.Score <= 9 ~ "8.5 - 9",
    Happiness.Score > 9 & Happiness.Score <= 9.5 ~ "9 - 9.5",
    Happiness.Score > 9.5 & Happiness.Score <= 10 ~ "9.5 - 10"
    )
  ) |> drop_na(Region)

```

```{r}
# 2a. Create region and happiness score world happiness index relative
# frequency table
# 2b. Call tabyl function with region as row and happiness score as column
# 2e. Add marginal totals
# 2f. Add percentages
# 2g. Set decimals to two places
# 2h. Add row and column titles
world_happy_freq <- total_data_summary_region |>
  tabyl(
    Region, binned.happiness.score
  ) |> adorn_totals(
    where = c("row", "col")
  ) |> adorn_percentages(
    denominator = "all"
  ) |> adorn_pct_formatting(
    digits = 2
  ) |> adorn_title(
    placement = "combined",
    row_name = "Region",
    col_name = "Happiness Score"
  )

```

```{r}
#| label: tbl-regionvhappinessscore
#| tbl-cap: "Region and Happiness Score Frequency Table"
#| tbl-pos: H
#| lst-label: lst-table1
#| lst-cap: "Code Chunk for Making Region/Happiness Freq Table"
# 3a. Polish region and happiness score relative frequency table
# 3b. Put percentages for each cell in parentheses
# 3c. Add commas to numbers over nine hundred and ninety nine
# 3d. Add counts
# 3e. Add title and kableExtra for styling
formatNs <-
  attr(
    world_happy_freq, "core"
  ) |> adorn_totals(
    where = c("row", "col")
  ) |> mutate(
    across(where(is.numeric), \(x) format(x, big.mark = ",", na.rm = TRUE))
  )

world_happy_freq <- world_happy_freq |>
  adorn_ns(
    position = "front", ns = formatNs
  )

world_happy_freq |>
  kable(
    caption = "Region and Happiness Score of Countires in the World Happiness Index 2015 - 2019",
    booktabs = TRUE,
    align = c("l", rep("c", 6))
  ) |> kableExtra::kable_styling(
    bootstrap_options = c("striped", "condensed"),
    font_size = 3
  )

**Key Insights:**

**Regional Happiness Clusters Persist Over Time (from 2015-2019):**

Regions such as Australia/NZ (100% in the 6.5-7.5 range) and Western Europe (~67.96% in the 6.5-8 range) consistently rank the highest, suggesting long-established advantages like strong GDP, social support, etc. 

There is also a low score stability with a region like Sub-Saharan Africa which dominates the bottom tiers (21.1% in the 2.5-3.5 range), indicating persistent challenges such as limited infrastructure investments, and political instability. 

**There is Limited Mobility Between Tiers:**

While there are some regions such as the Middle East/North Africa and Latin America, that show a moderate spread across the mid-range scores, indicating some form of change, there are no countries that transitioned from the bottom quartile (<4) to the top quartile (>6) or vice versa. 

This answers our first research question, proving that happiness is consistent and that there is little change when it comes to happiness scores over time. The countries that had an initially high-score continue to consistently stay high and similarly the countries that initially had low score consistently have stayed in the lower quartile, showing that there long-term factors such as GDP and governance that plays a role in short-term fluctuations. 

```
In @tbl-regionvhappinessscore

## Visualization 2 - Scatter plot of Happiness Score v Birth Rate

This visualization explores the relationship between national birth rates (per 1,000 people) and happiness scores of over 150+ countries from 2015-2019 to test the hypothesis that higher birth rates may strain resources and lower happiness.

```{r}
## Visualization 2 - Scatter plot of Happiness Score v Birth Rate


# Goal: Create a scatter plot of the birth rate versus the country's happiness score. 

# Need: merged data set of world happiness index data and world bank data

# Plan
# 1a. Create a scatter plot of birth rate versus the country's happiness
# score.
# 1b. Specify the wrangled data to be used, the x axis, the y
# axis, and what the color of each point is based on, the happiness score
# 1c. Specify aesthetic geometry, point
# 1d. Create a linear trend line with no confidence interval, set the color
# to black, and set the line width
# 1e. Add labels to the x axis, y axis, color, and the title, add black and
# white theme

```

```{r}
#| label: fig-finalbirthrateplot
#| fig-cap: "Happiness Score versus Birth Rate"
#| fig-alt: "Final Scatterplot of happiness score v birth rate"
#| lst-cap: "Code Chunk for Making Final Happiness Score v Birth Rate Figure"
#| fig-pos: H
#| fig-height: 5
# 1a. Create a scatter plot of birth rate versus the country's happiness
# score.
# 1b. Specify the wrangled data to be used, the x axis, the y
# axis, and what the color of each point is based on, the happiness score
# 1c. Specify aesthetic geometry, point
# 1d. Create a linear trend line with no confidence interval, set the color
# to black, and set the line width
# 1e. Add labels to the x axis, y axis, color, and the title, add black and
# white theme
ggplot(
  data = merged_data,
  mapping = aes(
    x = birth.rate,
    y = Happiness.Score,
    color = Happiness.Score
  )
) + geom_point(
  size = 2
) + geom_smooth(
  method = lm,
  formula = y ~ x,
  se = FALSE,
  col = '#000000',
  linewidth = 2
) + labs(
  x = "Birth Rate",
  y = "Happiness Score",
  color = "Happiness Score",
  title = "Happiness Score v Birth Rate"
) + theme_bw()


```
**Key Insights:**

-   **Strong Negative Correlation** (r = -0.72):

    -   Countries with birth rates (\>25) cluster in low happiness scores (3-5), while those with birth rates (\<15) score above 6.

-   **Socioeconomic Factors:**

    -   We can see that nations with a low birth rate are the ones that are happier, and from our previous visualizations, we can incur that regions with universal secondary education and with highly urbanized societies (ex. Australia/NZ, Western Europe, etc.) are the happiest and these are the regions that also have a low birth rate.

    -   In the same way, we can also come to the conclusion that the regions with a high birth rate have a lower happiness score and that these regions can also have issues such as political instability and a lower GDP.

In @fig-finalbirthrateplot

## Visualization 3 - Line Plot of Happiness Score over time between the Top 5 and Bottom 5 Countries

The line chart tracks happiness scores over five years for the top and bottom 5 countries in the world happiness index rankings. This visualization can help show us whether countries are resistant to change in happiness scores or not.
```{r}

## Visualization 3 - Line Plot of Happiness Score over time between the Top 5 and Bottom 5 Countries


# Goal: Obtain the Top 5 happiest countries and 
# the Bottom 5 happiest countries in 2015. Compare
# those countries with where they appear on this 
# chart in 2019. Evaluate the increases and decreases
# that occur between those 4 years.

# Need: the cleaned 2015 and 2019 data from the World Bank Data set

# Plan
# 1a. Insert the ggplot2 and dplyr libraries
# 2a. Create a variable for the top 5 countries in 2015
# 2b. Isolate those countries by arranging the Happiness Score
# in descending order. Then, taking each country from 1-5. Then,
# taking the name of each Country
# 3a. Create a variable for the bottom 5 countries in 2015
# 3b. Isolate those countries by arranging the Happiness Score.
# Then, taking each country from 1-5. Then,
# taking the name of each Country
# 4a. Combine the top 5 and bottom 5 variables into one 
# variable named Countries
# 5a. Create a new variable containing the data for each country
# 5b. Firstly, we want to combine the rows from the 2015 and 2019
# data set. Then, filter the data by the name of the countries.
# Next, group by the country and the year, which would show each 
# country twice: the score in 2015 and the score in 2019. Lastly,
# summarize each by the mean Happiness Score
# 6a. Create the line plot
# 6b. Set the x and y axis, the geometry of each mark, and assign each country
# to a color, making it easier to differenciate. 
# 6c. Add the labels for each axis, and the title

```

```{r}

# 1a. Insert the ggplot2 and dplyr libraries
library(ggplot2) 
library(dplyr)

```

```{r}

# 2a. Create a variable for the top 5 countries in 2015
# 2b. Isolate those countries by arranging the Happiness Score
# in descending order. Then, taking each country from 1-5. Then,
# taking the name of each Country
top5 <- data_2015 %>% 
  arrange(desc(Happiness.Score)) %>% 
  slice(1:5) %>%
  pull(Country) 

```

```{r}

# 3a. Create a variable for the bottom 5 countries in 2015
# 3b. Isolate those countries by arranging the Happiness Score.
# Then, taking each country from 1-5. Then,
# taking the name of each Country
bottom5 <- data_2015 %>% 
  arrange(Happiness.Score) %>%
  slice(1:5) %>%
  pull(Country)

```

```{r}

# 4a. Combine the top 5 and bottom 5 variables into one 
# variable named countries
countries <- c(top5, bottom5) 

```

```{r}

# 5a. Create a new variable containing the data for each country
# 5b. Firstly, we want to combine the rows from the 2015 and 2019
# data set. Then, filter the data by the name of the countries.
# Next, group by the country and the year, which would show each 
# country twice: the score in 2015 and the score in 2019. Lastly,
# summarize each by the mean Happiness Score
countries_data <- bind_rows(data_2015, data_2019) %>%
  filter(Country %in% countries) %>% 
  group_by(Country, Year) %>%
  summarize(score=mean(Happiness.Score), .groups='drop') 

```

```{r}
#| label: fig-finalhappinessovertimeplot
#| fig-cap: "Happiness Score Change between the top 5 and bottom 5 Countries in 2015 vs. 2019"
#| fig-alt: "Final Line plot of happiness score over time"
#| lst-cap: "Code Chunk for Making Final Happiness Score over time"
#| fig-pos: H
#| fig-height: 5
# 6a. Create the line plot
# 6b. Set the x and y axis, the geometry of each mark, and assign each country
# to a color, making it easier to differenciate. 
# 6c. Add the labels for each axis, and the title
ggplot(countries_data, aes(x = Year, y = score, color = Country)) +
  geom_line(size = 1.2) +  #adjusting the thickness of the line                                    
  scale_color_manual(values = c("#FF0000", "#00FF00", "#0000FF", "#FFFF00", "#FF00FF",
                                "#00FFFF", "#800000", "#008000", "#000080", "#808000")) + #customizing colors for each name
  labs(
    title = "Happiness Score Change between the top 5 and bottom 5 Countries in 2015 vs. 2019",
    x = "Year",
    y = "Happiness Score ",
    color = "Country"
  ) +
  theme_minimal()         

```
**Key Insights:**

-   **Distinct Trend Lines:**

    -   We can see that the top 5 countries are all nearly horizontal and are tightly clustered between scores 7.2-7.6, confirming stability. The bottom 5 lines are also almost clustered together in the 3.0-3.9 range, with some outliers like the country of Benin that shows a strong upward trend.

-   **Economic Shifts:**

    -   We can notice that all the top five countries seem to have a small downward trend starting from 2017, which can suggest a global issue, which has affected these major countries, hence the reason why there is no outlier, because all the countries are following a similar trend.

    -   We can also see that there are some outliers in the bottom five, like the country of Benin and Togo, which shows us that there are efforts being made in their respective governments for the betterment of society.

-   But even if the countries in the bottom five do seem to have an upward trend, we can see that the difference in scores between the top and bottom five are still drastic at the end of the five-year time period, suggesting that there is still some form of consistency between the scores.

In @fig-finalhappinessovertimeplot

## Conclusion

This project’s analysis of global happiness data reveals two critical insights:

1.  **Happiness is Persistent Over Time:**

    -   The happiest countries maintained their high scores with minimal fluctuations, while the least happy remained stagnant. **Only a few exceptions, like Benin, showed meaningful improvement**, suggesting that well-being is deeply tied to long-term structural factors like governance, economic stability, and social trust.

2.  **Birth Rates and Happiness Are Strongly Linked**

    -   Higher birth rates correlate with lower happiness, reflecting challenges like limited resources and gender inequality. However, **wealth and policy can override this trend**, as seen in Gulf States with moderate happiness despite higher birth rates.

In the end, we can come to the conclusion that happiness is not static, but meaningful change requires systemic investment and not just short-term fixes. The visualizations confirm that while outliers exist, **most nations remain locked in their happiness tier over time**.

## References

“World Happiness Report.” www.kaggle.com,

      www.kaggle.com/datasets/unsdsn/world-happiness.


González, Ariel. “World Bank World Development Indicators.”

      Kaggle.com, 2022,
      
      www.kaggle.com/datasets/nicolasgonzalezmunoz/world-bank-
      
      world-development-indicators?resource=download.

## Code Appendix

```{r codeAppend, ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE}
```
